{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1081d867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Active Learning Loop with Convergence Checking and Final Model Training ===\n",
    "# Console: English; Comments: English\n",
    "# Run this cell directly in VSCode / Jupyter.\n",
    "\n",
    "import sys\n",
    "import traceback\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# --- Project imports ---\n",
    "from config import Config\n",
    "from oracle import Oracle\n",
    "from inference import run_inference_cycle, cleanup_gpu, ConvergenceTracker, save_convergence_history\n",
    "from trainer import Trainer\n",
    "from dataset import create_dataloaders\n",
    "from template_graph_builder import TemplateGraphBuilder\n",
    "from model import create_model_from_config, count_parameters\n",
    "from utils import get_node_input_dim, save_model_for_inference\n",
    "\n",
    "# --- Optional Weights & Biases support ---\n",
    "try:\n",
    "    import wandb\n",
    "    WANDB_AVAILABLE = True\n",
    "except ImportError:\n",
    "    WANDB_AVAILABLE = False\n",
    "\n",
    "# ============================================================================\n",
    "# Setup Main Logger\n",
    "# ============================================================================\n",
    "\n",
    "def setup_main_logger(config: Config):\n",
    "    \"\"\"Setup main logger for active learning loop.\"\"\"\n",
    "    logger = logging.getLogger(\"active_learning\")\n",
    "    logger.setLevel(getattr(logging, config.log_level.upper()))\n",
    "    logger.handlers = []  # Clear existing handlers\n",
    "    \n",
    "    # File handler\n",
    "    log_file = Path(config.log_dir) / \"active_learning.log\"\n",
    "    log_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "    fh = logging.FileHandler(log_file)\n",
    "    fh.setLevel(getattr(logging, config.log_level.upper()))\n",
    "    \n",
    "    # Console handler\n",
    "    if config.log_to_console:\n",
    "        ch = logging.StreamHandler()\n",
    "        ch.setLevel(getattr(logging, config.log_level.upper()))\n",
    "    \n",
    "    # Formatter\n",
    "    formatter = logging.Formatter(\n",
    "        '%(asctime)s | %(levelname)-8s | %(message)s',\n",
    "        datefmt='%Y-%m-%d %H:%M:%S'\n",
    "    )\n",
    "    fh.setFormatter(formatter)\n",
    "    if config.log_to_console:\n",
    "        ch.setFormatter(formatter)\n",
    "    \n",
    "    # Add handlers\n",
    "    logger.addHandler(fh)\n",
    "    if config.log_to_console:\n",
    "        logger.addHandler(ch)\n",
    "    \n",
    "    return logger\n",
    "\n",
    "# ============================================================================\n",
    "# Helper functions\n",
    "# ============================================================================\n",
    "\n",
    "def is_csv_missing_or_empty(csv_path: str) -> bool:\n",
    "    \"\"\"Check if the CSV file is missing or empty.\"\"\"\n",
    "    p = Path(csv_path)\n",
    "    if not p.exists():\n",
    "        return True\n",
    "    try:\n",
    "        df = pd.read_csv(p)\n",
    "        return len(df) == 0\n",
    "    except Exception:\n",
    "        return True\n",
    "\n",
    "\n",
    "def sample_simplex_uniform(n: int, k: int) -> np.ndarray:\n",
    "    \"\"\"Sample n points uniformly on a (k-1)-simplex using Dirichlet distribution.\"\"\"\n",
    "    return np.random.dirichlet(alpha=np.ones(k), size=n)\n",
    "\n",
    "\n",
    "def initial_data_creation_if_needed(config: Config, oracle: Oracle, logger: logging.Logger):\n",
    "    \"\"\"\n",
    "    Create an initial dataset if CSV is missing or empty.\n",
    "    Uses config.al_initial_samples to determine the number of samples.\n",
    "    \"\"\"\n",
    "    csv_path = config.csv_path\n",
    "    if not is_csv_missing_or_empty(csv_path):\n",
    "        logger.info(f\"Database found: {csv_path}\")\n",
    "        return\n",
    "\n",
    "    elements = list(getattr(config, \"elements\", []))\n",
    "    n_seed = int(getattr(config, \"al_initial_samples\", 0) or 0)\n",
    "    if not elements or n_seed <= 0:\n",
    "        raise RuntimeError(\n",
    "            \"Initial data creation requires 'elements' and 'al_initial_samples' > 0 in config.\"\n",
    "        )\n",
    "\n",
    "    logger.info(\"=\"*70)\n",
    "    logger.info(\"INITIAL DATA CREATION (CSV empty or not found)\")\n",
    "    logger.info(\"=\"*70)\n",
    "    logger.info(f\"Elements: {elements}\")\n",
    "    logger.info(f\"Samples to create: {n_seed}\")\n",
    "    logger.info(f\"Target CSV: {csv_path}\")\n",
    "\n",
    "    weights = sample_simplex_uniform(n_seed, len(elements))\n",
    "    compositions = []\n",
    "    for row in weights:\n",
    "        comp = {el: float(val) for el, val in zip(elements, row)}\n",
    "        s = sum(comp.values())\n",
    "        if abs(s - 1.0) > 1e-12:\n",
    "            for el in comp:\n",
    "                comp[el] /= s\n",
    "        compositions.append(comp)\n",
    "\n",
    "    successes = 0\n",
    "    for i, comp in enumerate(compositions, 1):\n",
    "        try:\n",
    "            logger.info(f\"  [{i}/{n_seed}] Calculating: {comp}\")\n",
    "            ok = oracle.calculate(comp)\n",
    "            if ok is not False:\n",
    "                successes += 1\n",
    "        except Exception as e:\n",
    "            logger.error(f\"   Error at sample {i}: {e}\")\n",
    "\n",
    "    if successes == 0:\n",
    "        raise RuntimeError(\"Initial data creation failed: no valid samples added.\")\n",
    "    logger.info(f\"Initial data creation completed. {successes} samples added.\")\n",
    "\n",
    "\n",
    "def get_database_stats(csv_path: str) -> dict:\n",
    "    \"\"\"Return summary statistics for the current database CSV.\"\"\"\n",
    "    p = Path(csv_path)\n",
    "    if not p.exists():\n",
    "        return {\"n_samples\": 0, \"n_compositions\": 0}\n",
    "    try:\n",
    "        df = pd.read_csv(p)\n",
    "    except Exception:\n",
    "        return {\"n_samples\": 0, \"n_compositions\": 0}\n",
    "    return {\n",
    "        \"n_samples\": len(df),\n",
    "        \"n_compositions\": df['composition_string'].nunique() if 'composition_string' in df.columns else 0\n",
    "    }\n",
    "\n",
    "\n",
    "def train_cycle_model(config: Config, cycle: int, logger: logging.Logger, is_final: bool = False) -> dict:\n",
    "    \"\"\"Train the model for the given active learning cycle.\"\"\"\n",
    "    logger.info(\"=\"*70)\n",
    "    if is_final:\n",
    "        logger.info(\"TRAINING FINAL MODEL\")\n",
    "    else:\n",
    "        logger.info(f\"TRAINING MODEL - CYCLE {cycle}\")\n",
    "    logger.info(\"=\"*70)\n",
    "\n",
    "    outdir = Path(config.checkpoint_dir) / (\"final_model\" if is_final else f\"cycle_{cycle}\")\n",
    "    outdir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    try:\n",
    "        # Get current database size\n",
    "        db_stats = get_database_stats(config.csv_path)\n",
    "        n_samples = db_stats['n_samples']\n",
    "        \n",
    "        # Store dataset size in config for wandb naming\n",
    "        config._current_dataset_size = n_samples\n",
    "        \n",
    "        train_loader, val_loader = create_dataloaders(config)\n",
    "        builder = TemplateGraphBuilder(config)\n",
    "        node_input_dim = get_node_input_dim(builder)\n",
    "        model = create_model_from_config(config, node_input_dim)\n",
    "        \n",
    "        # Load best model from previous cycle if this is final training\n",
    "        if is_final:\n",
    "            # Find the cycle with best validation MAE\n",
    "            best_cycle = None\n",
    "            best_val_mae = float('inf')\n",
    "            \n",
    "            for c in range(cycle + 1):\n",
    "                cycle_path = Path(config.checkpoint_dir) / f\"cycle_{c}\" / \"best_model.pt\"\n",
    "                if cycle_path.exists():\n",
    "                    checkpoint = torch.load(cycle_path, map_location='cpu')\n",
    "                    val_mae = checkpoint.get('best_val_mae', float('inf'))\n",
    "                    if val_mae < best_val_mae:\n",
    "                        best_val_mae = val_mae\n",
    "                        best_cycle = c\n",
    "            \n",
    "            if best_cycle is not None:\n",
    "                best_model_path = Path(config.checkpoint_dir) / f\"cycle_{best_cycle}\" / \"best_model.pt\"\n",
    "                logger.info(f\"Loading best model from cycle {best_cycle} (val MAE: {best_val_mae:.4f})\")\n",
    "                checkpoint = torch.load(best_model_path, map_location='cpu')\n",
    "                model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        \n",
    "        # Create trainer\n",
    "        trainer = Trainer(model, config, save_dir=str(outdir), cycle=cycle, is_final_model=is_final)\n",
    "        trainer.train(train_loader, val_loader, verbose=True)\n",
    "        \n",
    "        logger.info(f\"Model training completed (Cycle {cycle})\" if not is_final else \"Final model training completed\")\n",
    "        \n",
    "        return {\n",
    "            'best_val_mae': trainer.best_val_mae,\n",
    "            'best_val_rel_mae': trainer.best_val_rel_mae\n",
    "        }\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Training failed: {e}\")\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "\n",
    "def active_learning_loop(config: Config, logger: logging.Logger):\n",
    "    \"\"\"Main active learning loop with convergence checking and final model training.\"\"\"\n",
    "    logger.info(\"=\"*70)\n",
    "    logger.info(\"ACTIVE LEARNING LOOP STARTING\")\n",
    "    logger.info(\"=\"*70)\n",
    "    logger.info(f\"Max cycles: {config.al_max_cycles}\")\n",
    "    logger.info(f\"Test samples per cycle: {config.al_n_test}\")\n",
    "    logger.info(f\"Query samples per cycle: {config.al_n_query}\")\n",
    "    logger.info(f\"Elements: {config.elements}\")\n",
    "    logger.info(f\"Convergence check: {config.al_convergence_check}\")\n",
    "    if config.al_convergence_check:\n",
    "        logger.info(f\"  Metric: {config.al_convergence_metric}\")\n",
    "        logger.info(f\"  MAE threshold: {config.al_convergence_threshold_mae} eV\")\n",
    "        logger.info(f\"  Rel MAE threshold: {config.al_convergence_threshold_rel_mae}\")\n",
    "        logger.info(f\"  Patience: {config.al_convergence_patience} cycles\")\n",
    "    logger.info(\"=\"*70)\n",
    "\n",
    "    oracle = Oracle(config)\n",
    "    initial_data_creation_if_needed(config, oracle, logger)\n",
    "    \n",
    "    # Initialize convergence tracker\n",
    "    convergence_tracker = ConvergenceTracker(config) if config.al_convergence_check else None\n",
    "    converged = False\n",
    "    last_cycle = 0\n",
    "\n",
    "    for cycle in range(config.al_max_cycles):\n",
    "        logger.info(\"=\"*70)\n",
    "        logger.info(f\"Cycle {cycle}/{config.al_max_cycles - 1}\")\n",
    "        logger.info(\"=\"*70)\n",
    "\n",
    "        db_stats = get_database_stats(config.csv_path)\n",
    "        logger.info(f\"Current database: {db_stats['n_samples']} samples, {db_stats['n_compositions']} compositions\")\n",
    "\n",
    "        # Model path logic\n",
    "        if cycle == 0:\n",
    "            logger.info(\"Training initial model ...\")\n",
    "            train_cycle_model(config, cycle, logger)\n",
    "        else:\n",
    "            prev_model = Path(config.checkpoint_dir) / f\"cycle_{cycle-1}\" / \"best_model.pt\"\n",
    "            if not prev_model.exists():\n",
    "                logger.warning(\"Previous model not found, training new model ...\")\n",
    "                train_cycle_model(config, cycle, logger)\n",
    "            else:\n",
    "                logger.info(f\"Using model: {prev_model}\")\n",
    "\n",
    "        # Determine current model path\n",
    "        current_model = Path(config.checkpoint_dir) / f\"cycle_{cycle}\" / \"best_model.pt\"\n",
    "        \n",
    "        # Run inference with convergence tracking\n",
    "        logger.info(\"Starting inference cycle ...\")\n",
    "        try:\n",
    "            selected, predictions = run_inference_cycle(\n",
    "                cycle, \n",
    "                str(current_model), \n",
    "                oracle, \n",
    "                config, \n",
    "                convergence_tracker=convergence_tracker,\n",
    "                verbose=True\n",
    "            )\n",
    "            \n",
    "            # Check convergence\n",
    "            if convergence_tracker is not None:\n",
    "                summary = convergence_tracker.get_summary()\n",
    "                if summary['converged']:\n",
    "                    logger.info(\"=\"*70)\n",
    "                    logger.info(\"CONVERGENCE ACHIEVED!\")\n",
    "                    logger.info(\"=\"*70)\n",
    "                    logger.info(f\"Best {config.al_convergence_metric.upper()}: \"\n",
    "                              f\"{summary['best_mae'] if config.al_convergence_metric == 'mae' else summary['best_rel_mae']:.4f}\")\n",
    "                    logger.info(f\"Cycles without improvement: {summary['cycles_without_improvement']}\")\n",
    "                    converged = True\n",
    "                    last_cycle = cycle\n",
    "                    \n",
    "                    # Save convergence history\n",
    "                    save_convergence_history(\n",
    "                        convergence_tracker,\n",
    "                        Path(config.al_results_dir) / \"convergence_history.json\"\n",
    "                    )\n",
    "                    break\n",
    "            \n",
    "            # After inference, train next model\n",
    "            if cycle < config.al_max_cycles - 1:\n",
    "                logger.info(\"Training model with new data ...\")\n",
    "                train_cycle_model(config, cycle + 1, logger)\n",
    "                \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Inference failed: {e}\")\n",
    "            traceback.print_exc()\n",
    "            continue\n",
    "\n",
    "        logger.info(f\"Cycle {cycle} completed.\")\n",
    "        last_cycle = cycle\n",
    "    \n",
    "    # Train final model with higher patience\n",
    "    logger.info(\"=\"*70)\n",
    "    if converged:\n",
    "        logger.info(\"TRAINING FINAL MODEL (after convergence)\")\n",
    "    else:\n",
    "        logger.info(\"TRAINING FINAL MODEL (max cycles reached)\")\n",
    "    logger.info(\"=\"*70)\n",
    "    logger.info(f\"Using higher patience: {config.final_model_patience} epochs\")\n",
    "    \n",
    "    final_results = train_cycle_model(config, last_cycle, logger, is_final=True)\n",
    "    \n",
    "    if final_results:\n",
    "        logger.info(f\"Final model best val MAE: {final_results['best_val_mae']:.4f} eV\")\n",
    "        logger.info(f\"Final model best val Rel MAE: {final_results['best_val_rel_mae']:.4f}\")\n",
    "    \n",
    "    logger.info(\"=\"*70)\n",
    "    logger.info(\"ACTIVE LEARNING COMPLETE\")\n",
    "    logger.info(\"=\"*70)\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Execution (show config + confirmation)\n",
    "# ============================================================================\n",
    "\n",
    "config = Config()\n",
    "\n",
    "# Setup main logger\n",
    "logger = setup_main_logger(config)\n",
    "\n",
    "# Print config summary for user review\n",
    "logger.info(\"=\"*70)\n",
    "logger.info(\"CURRENT CONFIG\")\n",
    "logger.info(\"=\"*70)\n",
    "for key, val in config.__dict__.items():\n",
    "    if not key.startswith('_'):\n",
    "        logger.info(f\"{key:30s}: {val}\")\n",
    "logger.info(\"=\"*70)\n",
    "\n",
    "confirm = input(\"Do you want to start the Active Learning workflow? (y/n): \").strip().lower()\n",
    "if confirm == \"y\":\n",
    "    try:\n",
    "        active_learning_loop(config, logger)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Run aborted: {e}\")\n",
    "        traceback.print_exc()\n",
    "else:\n",
    "    logger.info(\"Aborted - no execution started.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wandb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
