{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1081d867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================== AKTUELLE CONFIG ======================\n",
      "csv_path                 : database_navi.csv\n",
      "checkpoint_dir           : checkpoints\n",
      "database_dir             : database\n",
      "elements                 : ['Mo', 'Nb', 'Ta', 'W', 'Cr']\n",
      "supercell_size           : 4\n",
      "lattice_parameter        : 3.2\n",
      "cutoff_radius            : 3.5\n",
      "max_neighbors            : 50\n",
      "batch_size               : 32\n",
      "num_workers              : 0\n",
      "min_barrier              : 0.1\n",
      "max_barrier              : 15.0\n",
      "val_split                : 0.1\n",
      "random_seed              : 42\n",
      "gnn_hidden_dim           : 64\n",
      "gnn_num_layers           : 5\n",
      "gnn_embedding_dim        : 64\n",
      "mlp_hidden_dims          : [1024, 512, 256]\n",
      "dropout                  : 0.15\n",
      "learning_rate            : 0.0005\n",
      "weight_decay             : 0.01\n",
      "gradient_clip_norm       : 1.0\n",
      "epochs                   : 1000\n",
      "patience                 : 50\n",
      "save_interval            : 50\n",
      "use_scheduler            : True\n",
      "scheduler_type           : plateau\n",
      "scheduler_factor         : 0.5\n",
      "scheduler_patience       : 10\n",
      "scheduler_step_size      : 100\n",
      "scheduler_t_max          : 500\n",
      "scheduler_eta_min        : 1e-06\n",
      "neb_n_images             : 3\n",
      "neb_images               : 3\n",
      "neb_spring_constant      : 5.0\n",
      "neb_fmax                 : 0.05\n",
      "neb_max_steps            : 500\n",
      "neb_climb                : True\n",
      "neb_method               : aseneb\n",
      "relax_cell               : False\n",
      "relax_fmax               : 0.1\n",
      "relax_steps              : 500\n",
      "relax_max_steps          : 500\n",
      "al_initial_samples       : 50\n",
      "al_n_test                : 100\n",
      "al_test_strategy         : uniform\n",
      "al_n_query               : 20\n",
      "al_query_strategy        : error_weighted\n",
      "al_max_cycles            : 10\n",
      "al_seed                  : 42\n",
      "al_results_dir           : active_learning_results\n",
      "use_wandb                : True\n",
      "wandb_project            : diffusion-barrier\n",
      "wandb_entity             : None\n",
      "wandb_run_name           : None\n",
      "wandb_tags               : []\n",
      "wandb_notes              : \n",
      "wandb_log_interval       : 1\n",
      "wandb_watch_model        : True\n",
      "wandb_watch_freq         : 100\n",
      "==============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# === Active Learning Loop with Initial Data Creation and Start Confirmation ===\n",
    "# Console: German; Comments: English\n",
    "# Run this cell directly in VSCode / Jupyter.\n",
    "\n",
    "import sys\n",
    "import traceback\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# --- Project imports ---\n",
    "from config import Config\n",
    "from oracle import Oracle\n",
    "from inference import run_inference_cycle, cleanup_gpu\n",
    "from trainer import Trainer\n",
    "from dataset import create_dataloaders\n",
    "from template_graph_builder import TemplateGraphBuilder\n",
    "from model import create_model_from_config, count_parameters\n",
    "from utils import get_node_input_dim, save_model_for_inference\n",
    "\n",
    "# --- Optional Weights & Biases support ---\n",
    "try:\n",
    "    import wandb\n",
    "    WANDB_AVAILABLE = True\n",
    "except ImportError:\n",
    "    WANDB_AVAILABLE = False\n",
    "\n",
    "# ============================================================================\n",
    "# Helper functions\n",
    "# ============================================================================\n",
    "\n",
    "def is_csv_missing_or_empty(csv_path: str) -> bool:\n",
    "    \"\"\"Check if the CSV file is missing or empty.\"\"\"\n",
    "    p = Path(csv_path)\n",
    "    if not p.exists():\n",
    "        return True\n",
    "    try:\n",
    "        df = pd.read_csv(p)\n",
    "        return len(df) == 0\n",
    "    except Exception:\n",
    "        return True\n",
    "\n",
    "\n",
    "def sample_simplex_uniform(n: int, k: int) -> np.ndarray:\n",
    "    \"\"\"Sample n points uniformly on a (k-1)-simplex using Dirichlet distribution.\"\"\"\n",
    "    return np.random.dirichlet(alpha=np.ones(k), size=n)\n",
    "\n",
    "\n",
    "def initial_data_creation_if_needed(config: Config, oracle: Oracle):\n",
    "    \"\"\"\n",
    "    Create an initial dataset if CSV is missing or empty.\n",
    "    Uses config.al_initial_samples to determine the number of samples.\n",
    "    \"\"\"\n",
    "    csv_path = config.csv_path\n",
    "    if not is_csv_missing_or_empty(csv_path):\n",
    "        print(f\"✓ Datenbank gefunden: {csv_path}\")\n",
    "        return\n",
    "\n",
    "    elements = list(getattr(config, \"elements\", []))\n",
    "    n_seed = int(getattr(config, \"al_initial_samples\", 0) or 0)\n",
    "    if not elements or n_seed <= 0:\n",
    "        raise RuntimeError(\n",
    "            \"Initial data creation requires 'elements' and 'al_initial_samples' > 0 in config.\"\n",
    "        )\n",
    "\n",
    "    print(\"\\n======================================================================\")\n",
    "    print(\"ERSTELLUNG INITIALER DATEN (CSV leer oder nicht vorhanden)\")\n",
    "    print(\"======================================================================\")\n",
    "    print(f\"Elemente: {elements}\")\n",
    "    print(f\"Zu erstellende Samples: {n_seed}\")\n",
    "    print(f\"Ziel-CSV: {csv_path}\")\n",
    "\n",
    "    weights = sample_simplex_uniform(n_seed, len(elements))\n",
    "    compositions = []\n",
    "    for row in weights:\n",
    "        comp = {el: float(val) for el, val in zip(elements, row)}\n",
    "        s = sum(comp.values())\n",
    "        if abs(s - 1.0) > 1e-12:\n",
    "            for el in comp:\n",
    "                comp[el] /= s\n",
    "        compositions.append(comp)\n",
    "\n",
    "    successes = 0\n",
    "    for i, comp in enumerate(compositions, 1):\n",
    "        try:\n",
    "            print(f\"  [{i}/{n_seed}] Berechne: {comp}\")\n",
    "            ok = oracle.calculate(comp)\n",
    "            if ok is not False:\n",
    "                successes += 1\n",
    "        except Exception as e:\n",
    "            print(f\"   ✗ Fehler bei Sample {i}: {e}\")\n",
    "\n",
    "    if successes == 0:\n",
    "        raise RuntimeError(\"Initial data creation failed: no valid samples added.\")\n",
    "    print(f\"\\n✓ Initiale Datenerstellung abgeschlossen. {successes} Samples hinzugefügt.\\n\")\n",
    "\n",
    "\n",
    "def get_database_stats(csv_path: str) -> dict:\n",
    "    \"\"\"Return summary statistics for the current database CSV.\"\"\"\n",
    "    p = Path(csv_path)\n",
    "    if not p.exists():\n",
    "        return {\"n_samples\": 0, \"n_compositions\": 0}\n",
    "    try:\n",
    "        df = pd.read_csv(p)\n",
    "    except Exception:\n",
    "        return {\"n_samples\": 0, \"n_compositions\": 0}\n",
    "    return {\n",
    "        \"n_samples\": len(df),\n",
    "        \"n_compositions\": df['composition_string'].nunique() if 'composition_string' in df.columns else 0\n",
    "    }\n",
    "\n",
    "\n",
    "def train_cycle_model(config: Config, cycle: int) -> dict:\n",
    "    \"\"\"Train the model for the given active learning cycle.\"\"\"\n",
    "    print(\"\\n======================================================================\")\n",
    "    print(f\"TRAINING MODEL - ZYKLUS {cycle}\")\n",
    "    print(\"======================================================================\")\n",
    "\n",
    "    outdir = Path(config.checkpoint_dir) / f\"cycle_{cycle}\"\n",
    "    outdir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    try:\n",
    "        train_loader, val_loader = create_dataloaders(config)\n",
    "        builder = TemplateGraphBuilder(config)\n",
    "        node_input_dim = get_node_input_dim(builder)\n",
    "        model = create_model_from_config(config, node_input_dim)\n",
    "        trainer = Trainer(model, config, save_dir=str(outdir))\n",
    "        trainer.train(train_loader, val_loader, verbose=True)\n",
    "        print(f\"✓ Modelltraining abgeschlossen (Zyklus {cycle})\")\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Training fehlgeschlagen: {e}\")\n",
    "        traceback.print_exc()\n",
    "\n",
    "\n",
    "def active_learning_loop(config: Config):\n",
    "    \"\"\"Main active learning loop with initial data creation.\"\"\"\n",
    "    print(\"\\n======================================================================\")\n",
    "    print(\"AKTIVER LERNZYKLUS STARTET\")\n",
    "    print(\"======================================================================\")\n",
    "    print(f\"Zyklen: {config.al_max_cycles}\")\n",
    "    print(f\"Samples pro Test: {config.al_n_test}\")\n",
    "    print(f\"Samples pro Abfrage: {config.al_n_query}\")\n",
    "    print(f\"Elemente: {config.elements}\")\n",
    "    print(\"======================================================================\\n\")\n",
    "\n",
    "    oracle = Oracle(config)\n",
    "    initial_data_creation_if_needed(config, oracle)\n",
    "\n",
    "    for cycle in range(config.al_max_cycles):\n",
    "        print(f\"\\n======================================================================\")\n",
    "        print(f\"Zyklus {cycle}/{config.al_max_cycles}\")\n",
    "        print(\"======================================================================\")\n",
    "\n",
    "        db_stats = get_database_stats(config.csv_path)\n",
    "        print(f\"Aktuelle Datenbank: {db_stats['n_samples']} Samples, {db_stats['n_compositions']} Kompositionen\")\n",
    "\n",
    "        # Model path logic\n",
    "        if cycle == 0:\n",
    "            print(\"→ Trainiere initiales Modell ...\")\n",
    "            train_cycle_model(config, cycle)\n",
    "        else:\n",
    "            prev_model = Path(config.checkpoint_dir) / f\"cycle_{cycle-1}\" / \"best_model.pt\"\n",
    "            if not prev_model.exists():\n",
    "                print(\"⚠️ Vorheriges Modell nicht gefunden, trainiere neu ...\")\n",
    "                train_cycle_model(config, cycle)\n",
    "            else:\n",
    "                print(f\"→ Verwende Modell: {prev_model}\")\n",
    "\n",
    "        # Run inference\n",
    "        print(\"→ Starte Inferenzzyklus ...\")\n",
    "        try:\n",
    "            run_inference_cycle(cycle, str(prev_model), oracle, config, verbose=True)\n",
    "        except Exception as e:\n",
    "            print(f\"✗ Inferenz fehlgeschlagen: {e}\")\n",
    "            traceback.print_exc()\n",
    "            continue\n",
    "\n",
    "        print(f\"✓ Zyklus {cycle} abgeschlossen.\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Execution (show config + confirmation)\n",
    "# ============================================================================\n",
    "\n",
    "config = Config()\n",
    "\n",
    "# Print config summary for user review\n",
    "print(\"\\n====================== AKTUELLE CONFIG ======================\")\n",
    "for key, val in config.__dict__.items():\n",
    "    print(f\"{key:25s}: {val}\")\n",
    "print(\"==============================================================\\n\")\n",
    "\n",
    "confirm = input(\"❓ Willst du den Active-Learning-Workflow wirklich starten? (y/n): \").strip().lower()\n",
    "if confirm == \"y\":\n",
    "    try:\n",
    "        active_learning_loop(config)\n",
    "    except Exception as e:\n",
    "        print(f\"\\n✗ Lauf abgebrochen: {e}\")\n",
    "        traceback.print_exc()\n",
    "else:\n",
    "    print(\"↪️  Abgebrochen — keine Ausführung gestartet.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wandb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
