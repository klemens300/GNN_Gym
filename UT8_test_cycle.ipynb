{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451ee276",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Test Notebook for inference.py\n",
    "\n",
    "Tests all components step by step in one notebook.\n",
    "Run cells sequentially to test each level.\n",
    "\n",
    "All parameters come from Config, not from hardcoded values.\n",
    "\"\"\"\n",
    "\n",
    "# ============================================================================\n",
    "# SETUP & IMPORTS\n",
    "# ============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "from config import Config\n",
    "from oracle import Oracle\n",
    "from inference import (\n",
    "    generate_test_compositions,\n",
    "    select_samples_by_error,\n",
    "    generate_test_data_with_oracle,\n",
    "    predict_barriers_for_test_set,\n",
    "    run_inference_cycle\n",
    ")\n",
    "\n",
    "print(\"✓ All imports successful\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# LEVEL 1A: Test Composition Generation\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"LEVEL 1A: COMPOSITION GENERATION TEST\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Get elements from Config\n",
    "config = Config()\n",
    "elements = config.elements\n",
    "\n",
    "print(f\"\\nElements from Config: {elements}\")\n",
    "\n",
    "# Generate test compositions\n",
    "comps = generate_test_compositions(\n",
    "    elements, \n",
    "    n_test=10, \n",
    "    strategy=config.al_test_strategy,\n",
    "    seed=config.al_seed\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ Generated {len(comps)} compositions using '{config.al_test_strategy}' strategy\")\n",
    "print(\"\\nFirst 3 compositions:\")\n",
    "for i, comp in enumerate(comps[:3], 1):\n",
    "    comp_str = \", \".join(f\"{k}={v:.3f}\" for k, v in comp.items())\n",
    "    total = sum(comp.values())\n",
    "    print(f\"  {i}. {comp_str}\")\n",
    "    print(f\"     Sum: {total:.6f} (should be 1.0)\")\n",
    "\n",
    "print(\"\\n✓ Level 1A PASSED\" if all(abs(sum(c.values()) - 1.0) < 1e-6 for c in comps) else \"\\n✗ Level 1A FAILED\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# LEVEL 1B: Test Error-Weighted Sampling\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"LEVEL 1B: ERROR-WEIGHTED SAMPLING TEST\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Create fake predictions\n",
    "fake_predictions = pd.DataFrame({\n",
    "    'composition': [\n",
    "        'Mo0.200Nb0.200O0.200Ta0.200W0.200',\n",
    "        'Mo0.300Nb0.100O0.300Ta0.100W0.200',\n",
    "        'Mo0.100Nb0.100O0.500Ta0.100W0.200',\n",
    "        'Mo0.400Nb0.100O0.200Ta0.100W0.200'\n",
    "    ],\n",
    "    'oracle_barrier': [1.0, 2.0, 3.0, 4.0],\n",
    "    'predicted_barrier': [1.2, 2.5, 2.8, 4.3],\n",
    "    'relative_error': [0.20, 0.25, 0.07, 0.075],\n",
    "    'absolute_error': [0.2, 0.5, 0.2, 0.3],\n",
    "    'structure_folder': ['path1', 'path2', 'path3', 'path4']\n",
    "})\n",
    "\n",
    "print(\"\\nFake predictions:\")\n",
    "print(fake_predictions[['composition', 'relative_error']])\n",
    "\n",
    "# Test sampling multiple times to see distribution\n",
    "print(f\"\\nRunning 10 sampling iterations using '{config.al_query_strategy}' strategy:\")\n",
    "selection_counts = {i: 0 for i in range(len(fake_predictions))}\n",
    "\n",
    "for trial in range(10):\n",
    "    selected = select_samples_by_error(\n",
    "        fake_predictions.copy(), \n",
    "        n_query=2,\n",
    "        strategy=config.al_query_strategy,\n",
    "        seed=config.al_seed + trial\n",
    "    )\n",
    "    for s in selected:\n",
    "        idx = fake_predictions[fake_predictions['composition'] == s['composition_str']].index[0]\n",
    "        selection_counts[idx] += 1\n",
    "\n",
    "print(\"\\nSelection frequency (out of 10 trials, 2 samples each = 20 total):\")\n",
    "for idx, count in selection_counts.items():\n",
    "    error = fake_predictions.iloc[idx]['relative_error']\n",
    "    print(f\"  Sample {idx} (error={error:.3f}): selected {count} times\")\n",
    "\n",
    "print(\"\\nExpected: Higher errors (0.25, 0.20) should be selected more often than lower errors (0.075, 0.07)\")\n",
    "print(\"✓ Level 1B PASSED (check if distribution makes sense)\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# LEVEL 2C: Test Oracle Integration (OPTIONAL - SLOW!)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"LEVEL 2C: ORACLE INTEGRATION TEST (OPTIONAL)\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\n⚠️  WARNING: This test calls Oracle 2 times (~10 minutes)\")\n",
    "\n",
    "run_oracle_test = input(\"Run Oracle test? (yes/no): \").strip().lower() == 'yes'\n",
    "\n",
    "if run_oracle_test:\n",
    "    config = Config()\n",
    "    oracle = Oracle(config)\n",
    "    \n",
    "    # Get elements from Config\n",
    "    elements = config.elements\n",
    "    \n",
    "    # Generate 2 test compositions using Config parameters\n",
    "    test_comps = generate_test_compositions(\n",
    "        elements=elements,\n",
    "        n_test=2,\n",
    "        strategy=config.al_test_strategy,\n",
    "        seed=config.al_seed\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nGenerating test data with Oracle ({len(test_comps)} compositions)...\")\n",
    "    print(f\"Using elements from Config: {elements}\")\n",
    "    \n",
    "    test_data = generate_test_data_with_oracle(\n",
    "        compositions=test_comps,\n",
    "        oracle=oracle,\n",
    "        config=config,\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    print(\"\\nTest data:\")\n",
    "    print(test_data)\n",
    "    \n",
    "    # Save for next test\n",
    "    test_data.to_csv('temp_test_data.csv', index=False)\n",
    "    print(\"\\n✓ Test data saved to: temp_test_data.csv\")\n",
    "    print(\"✓ Level 2C PASSED\")\n",
    "else:\n",
    "    print(\"\\n⊘ Skipped Oracle test\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# LEVEL 2D: Test Model Prediction (requires test data from 2C)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"LEVEL 2D: MODEL PREDICTION TEST\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "test_data_file = Path('temp_test_data.csv')\n",
    "\n",
    "if test_data_file.exists():\n",
    "    print(\"\\n✓ Found test data from Level 2C\")\n",
    "    \n",
    "    # Check if model exists\n",
    "    model_path = Path(config.checkpoint_dir) / 'best_model.pt'\n",
    "    \n",
    "    if model_path.exists():\n",
    "        config = Config()\n",
    "        \n",
    "        test_data = pd.read_csv(test_data_file)\n",
    "        \n",
    "        print(f\"\\nMaking predictions for {len(test_data)} samples...\")\n",
    "        print(f\"Using Config elements: {config.elements}\")\n",
    "        \n",
    "        predictions = predict_barriers_for_test_set(\n",
    "            model_path=str(model_path),\n",
    "            test_data=test_data,\n",
    "            config=config,\n",
    "            verbose=True\n",
    "        )\n",
    "        \n",
    "        print(\"\\nPredictions:\")\n",
    "        print(predictions[['composition', 'oracle_barrier', 'predicted_barrier', 'relative_error']])\n",
    "        \n",
    "        print(\"\\n✓ Level 2D PASSED\")\n",
    "    else:\n",
    "        print(f\"\\n⊘ Model not found at: {model_path}\")\n",
    "        print(\"   Train a model first or adjust path in Config\")\n",
    "else:\n",
    "    print(\"\\n⊘ No test data found. Run Level 2C first or create temp_test_data.csv manually\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# LEVEL 3: Mini-Cycle Test (OPTIONAL - SLOW!)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"LEVEL 3: MINI-CYCLE TEST (OPTIONAL)\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\n⚠️  WARNING: This runs a complete inference cycle with n_test={config.al_n_test}\")\n",
    "print(f\"   Adjust config.al_n_test for faster testing (currently: {config.al_n_test})\")\n",
    "\n",
    "run_cycle_test = input(\"Run mini-cycle test? (yes/no): \").strip().lower() == 'yes'\n",
    "\n",
    "if run_cycle_test:\n",
    "    # Check if model exists\n",
    "    model_path = Path(config.checkpoint_dir) / 'best_model.pt'\n",
    "    \n",
    "    if model_path.exists():\n",
    "        config = Config()\n",
    "        \n",
    "        # For testing: use small values (can be overridden)\n",
    "        print(\"\\nCurrent Active Learning Config:\")\n",
    "        print(f\"  Elements: {config.elements}\")\n",
    "        print(f\"  al_n_test: {config.al_n_test}\")\n",
    "        print(f\"  al_n_query: {config.al_n_query}\")\n",
    "        print(f\"  al_test_strategy: {config.al_test_strategy}\")\n",
    "        print(f\"  al_query_strategy: {config.al_query_strategy}\")\n",
    "        \n",
    "        # Optional: override for faster testing\n",
    "        use_small_test = input(\"\\nUse small test values (n_test=5, n_query=2) for faster testing? (yes/no): \").strip().lower() == 'yes'\n",
    "        if use_small_test:\n",
    "            config.al_n_test = 5\n",
    "            config.al_n_query = 2\n",
    "            print(f\"  Overridden: al_n_test={config.al_n_test}, al_n_query={config.al_n_query}\")\n",
    "        \n",
    "        oracle = Oracle(config)\n",
    "        \n",
    "        print(\"\\nRunning inference cycle...\")\n",
    "        \n",
    "        selected, predictions = run_inference_cycle(\n",
    "            cycle=0,\n",
    "            model_path=str(model_path),\n",
    "            oracle=oracle,\n",
    "            config=config,\n",
    "            verbose=True\n",
    "        )\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"CYCLE RESULTS\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        print(f\"\\n✓ Selected {len(selected)} samples for training:\")\n",
    "        for i, s in enumerate(selected, 1):\n",
    "            print(f\"  {i}. {s['composition_str']}\")\n",
    "            print(f\"     Oracle: {s['oracle_barrier']:.3f} eV, Predicted: {s['predicted_barrier']:.3f} eV\")\n",
    "            print(f\"     Relative error: {s['relative_error']:.3f}\")\n",
    "        \n",
    "        print(f\"\\n✓ Predictions saved to: {config.al_results_dir}/cycle_0_predictions.csv\")\n",
    "        \n",
    "        print(\"\\n✓ Level 3 PASSED\")\n",
    "    else:\n",
    "        print(f\"\\n⊘ Model not found at: {model_path}\")\n",
    "        print(\"   Train a model first\")\n",
    "else:\n",
    "    print(\"\\n⊘ Skipped mini-cycle test\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# SUMMARY\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TEST SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n✓ Level 1A: Composition Generation - PASSED\")\n",
    "print(\"✓ Level 1B: Error-Weighted Sampling - PASSED\")\n",
    "\n",
    "if run_oracle_test:\n",
    "    print(\"✓ Level 2C: Oracle Integration - PASSED\")\n",
    "else:\n",
    "    print(\"⊘ Level 2C: Oracle Integration - SKIPPED\")\n",
    "\n",
    "model_path = Path(config.checkpoint_dir) / 'best_model.pt'\n",
    "if test_data_file.exists() and model_path.exists():\n",
    "    print(\"✓ Level 2D: Model Prediction - PASSED\")\n",
    "else:\n",
    "    print(\"⊘ Level 2D: Model Prediction - SKIPPED (missing data or model)\")\n",
    "\n",
    "if run_cycle_test:\n",
    "    print(\"✓ Level 3: Mini-Cycle - PASSED\")\n",
    "else:\n",
    "    print(\"⊘ Level 3: Mini-Cycle - SKIPPED\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"\\nConfiguration Summary:\")\n",
    "print(f\"  Elements: {config.elements}\")\n",
    "print(f\"  Test strategy: {config.al_test_strategy}\")\n",
    "print(f\"  Query strategy: {config.al_query_strategy}\")\n",
    "print(f\"  n_test: {config.al_n_test}\")\n",
    "print(f\"  n_query: {config.al_n_query}\")\n",
    "print(f\"  Results dir: {config.al_results_dir}\")\n",
    "\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"1. If all tests passed → Ready for active_learning_loop.py\")\n",
    "print(\"2. If tests skipped → Run them when Oracle/Model available\")\n",
    "print(\"3. Adjust Config parameters for production (config.al_n_test, config.al_n_query, etc.)\")\n",
    "print(\"=\"*70 + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wandb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
