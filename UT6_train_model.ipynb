{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290a183a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Training Script for Diffusion Barrier Prediction - Jupyter Notebook Version\n",
    "\n",
    "Simple script to train a GNN model on diffusion barrier data in Jupyter.\n",
    "\n",
    "Usage in Jupyter:\n",
    "    %run train_notebook.py\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "from config import Config\n",
    "from template_graph_builder import TemplateGraphBuilder\n",
    "from dataset import create_dataloaders\n",
    "from model import create_model_from_config, count_parameters\n",
    "from trainer import Trainer\n",
    "from utils import save_model_for_inference, get_node_input_dim\n",
    "\n",
    "\n",
    "def train(config, save_dir: str = \"checkpoints\"):\n",
    "    \"\"\"\n",
    "    Main training function.\n",
    "    \n",
    "    Args:\n",
    "        config: Configuration object\n",
    "        save_dir: Directory to save checkpoints\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"DIFFUSION BARRIER PREDICTION - TRAINING\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"\\nDevice: {device}\")\n",
    "    \n",
    "    # ========================================================================\n",
    "    # 1. SETUP GRAPH BUILDER\n",
    "    # ========================================================================\n",
    "    print(\"\\n\" + \"-\"*70)\n",
    "    print(\"1. SETUP GRAPH BUILDER\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    builder = TemplateGraphBuilder(config)\n",
    "    node_input_dim = get_node_input_dim(builder)\n",
    "    \n",
    "    print(f\"\\n✓ Graph builder ready\")\n",
    "    print(f\"  Elements: {builder.elements}\")\n",
    "    print(f\"  Node input dim: {node_input_dim}\")\n",
    "    \n",
    "    # ========================================================================\n",
    "    # 2. CREATE MODEL\n",
    "    # ========================================================================\n",
    "    print(\"\\n\" + \"-\"*70)\n",
    "    print(\"2. CREATE MODEL\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    model = create_model_from_config(config, node_input_dim)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    params = count_parameters(model)\n",
    "    \n",
    "    print(f\"\\n✓ Model created\")\n",
    "    print(f\"  Architecture:\")\n",
    "    print(f\"    GNN layers: {config.gnn_num_layers}\")\n",
    "    print(f\"    GNN hidden dim: {config.gnn_hidden_dim}\")\n",
    "    print(f\"    MLP hidden dims: {config.mlp_hidden_dims}\")\n",
    "    print(f\"  Parameters:\")\n",
    "    print(f\"    Encoder: {params['encoder']:,}\")\n",
    "    print(f\"    Predictor: {params['predictor']:,}\")\n",
    "    print(f\"    Total: {params['total']:,}\")\n",
    "    \n",
    "    # ========================================================================\n",
    "    # 3. LOAD DATA\n",
    "    # ========================================================================\n",
    "    print(\"\\n\" + \"-\"*70)\n",
    "    print(\"3. LOAD DATA\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    train_loader, val_loader = create_dataloaders(\n",
    "        config,\n",
    "        val_split=config.val_split,\n",
    "        random_seed=config.random_seed\n",
    "    )\n",
    "    \n",
    "    # ========================================================================\n",
    "    # 4. TRAIN MODEL\n",
    "    # ========================================================================\n",
    "    print(\"\\n\" + \"-\"*70)\n",
    "    print(\"4. TRAIN MODEL\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    # Create trainer\n",
    "    trainer = Trainer(model, config, save_dir=save_dir)\n",
    "    \n",
    "    # Train\n",
    "    history = trainer.train(train_loader, val_loader, verbose=True)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # 5. SAVE FINAL MODEL\n",
    "    # ========================================================================\n",
    "    print(\"\\n\" + \"-\"*70)\n",
    "    print(\"5. SAVE FINAL MODEL\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    # Load best model\n",
    "    best_checkpoint_path = Path(save_dir) / \"best_model.pt\"\n",
    "    if best_checkpoint_path.exists():\n",
    "        trainer.load_checkpoint(str(best_checkpoint_path))\n",
    "        print(f\"\\n✓ Loaded best model from training\")\n",
    "    \n",
    "    # Save for inference\n",
    "    final_model_path = Path(save_dir) / \"final_model_for_inference.pt\"\n",
    "    save_model_for_inference(\n",
    "        model=trainer.model,\n",
    "        node_input_dim=node_input_dim,\n",
    "        elements=builder.elements,\n",
    "        config=config,\n",
    "        filepath=str(final_model_path),\n",
    "        metadata={\n",
    "            'best_val_loss': trainer.best_val_loss,\n",
    "            'total_epochs': trainer.current_epoch + 1,\n",
    "            'train_samples': len(train_loader.dataset),\n",
    "            'val_samples': len(val_loader.dataset) if val_loader else 0\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # ========================================================================\n",
    "    # 6. SUMMARY\n",
    "    # ========================================================================\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"TRAINING SUMMARY\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    print(f\"\\nTraining completed:\")\n",
    "    print(f\"  Total epochs: {trainer.current_epoch + 1}\")\n",
    "    print(f\"  Best val loss: {trainer.best_val_loss:.4f}\")\n",
    "    print(f\"  Train samples: {len(train_loader.dataset)}\")\n",
    "    if val_loader:\n",
    "        print(f\"  Val samples: {len(val_loader.dataset)}\")\n",
    "    \n",
    "    print(f\"\\nFiles saved:\")\n",
    "    print(f\"  Best checkpoint: {best_checkpoint_path}\")\n",
    "    print(f\"  Final model: {final_model_path}\")\n",
    "    print(f\"  History: {Path(save_dir) / 'training_history.json'}\")\n",
    "    \n",
    "    print(f\"\\nTo use this model for prediction:\")\n",
    "    print(f\"  from utils import load_model_for_inference\")\n",
    "    print(f\"  model, checkpoint = load_model_for_inference('{final_model_path}', config)\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70 + \"\\n\")\n",
    "    \n",
    "    return trainer, history\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# MAIN EXECUTION - Runs automatically when script is executed\n",
    "# ============================================================================\n",
    "\n",
    "# Create and configure\n",
    "config = Config()\n",
    "\n",
    "# Optional: Customize config here\n",
    "# config.epochs = 500\n",
    "# config.batch_size = 64\n",
    "# config.learning_rate = 0.001\n",
    "# config.use_wandb = True\n",
    "# config.wandb_run_name = \"my-experiment\"\n",
    "# config.wandb_tags = [\"baseline\", \"v1\"]\n",
    "\n",
    "# Run training\n",
    "print(\"Starting training with configuration:\")\n",
    "print(f\"  Epochs: {config.epochs}\")\n",
    "print(f\"  Batch size: {config.batch_size}\")\n",
    "print(f\"  Learning rate: {config.learning_rate}\")\n",
    "print(f\"  Scheduler: {config.scheduler_type}\")\n",
    "print(f\"  Wandb: {config.use_wandb}\")\n",
    "if config.use_wandb:\n",
    "    print(f\"  Wandb project: {config.wandb_project}\")\n",
    "    print(f\"  Wandb run name: {config.wandb_run_name or 'auto-generated'}\")\n",
    "\n",
    "trainer, history = train(config, save_dir=\"checkpoints\")\n",
    "\n",
    "print(\"\\n✓ Training completed! Trainer and history are available in variables.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wandb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
