{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290a183a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training with configuration:\n",
      "  Epochs: 1000\n",
      "  Batch size: 32\n",
      "  Learning rate: 0.0005\n",
      "  Scheduler: plateau\n",
      "  Wandb: True\n",
      "  Wandb project: diffusion-barrier\n",
      "  Wandb run name: auto-generated\n",
      "\n",
      "======================================================================\n",
      "DIFFUSION BARRIER PREDICTION - TRAINING\n",
      "======================================================================\n",
      "\n",
      "Device: cuda\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "1. SETUP GRAPH BUILDER\n",
      "----------------------------------------------------------------------\n",
      "✓ Detected elements from database: ['Mo', 'Nb', 'O', 'Ta', 'W']\n",
      "Building template graph...\n",
      "✓ Template created: 127 nodes, 1764 edges\n",
      "✓ Node features: 12 (pos: 3, one-hot: 5, props: 4)\n",
      "\n",
      "✓ Graph builder ready\n",
      "  Elements: ['Mo', 'Nb', 'O', 'Ta', 'W']\n",
      "  Node input dim: 12\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "2. CREATE MODEL\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "✓ Model created\n",
      "  Architecture:\n",
      "    GNN layers: 5\n",
      "    GNN hidden dim: 64\n",
      "    MLP hidden dims: [1024, 512, 256]\n",
      "  Parameters:\n",
      "    Encoder: 109,952\n",
      "    Predictor: 857,601\n",
      "    Total: 967,553\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "3. LOAD DATA\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "CREATING DATALOADERS\n",
      "======================================================================\n",
      "\n",
      "Loading data from: database_navi.csv\n",
      "Barrier filter: [0.1, 15.0] eV\n",
      "✓ Detected elements from database: ['Mo', 'Nb', 'O', 'Ta', 'W']\n",
      "Building template graph...\n",
      "✓ Template created: 127 nodes, 1764 edges\n",
      "✓ Node features: 12 (pos: 3, one-hot: 5, props: 4)\n",
      "Dataset loaded: 419 samples\n",
      "  Removed 779 samples (barrier filtering)\n",
      "\n",
      "Dataset statistics:\n",
      "  Samples: 419\n",
      "  Barrier range: [0.107, 14.917] eV\n",
      "  Barrier mean: 3.671 ± 4.475 eV\n",
      "\n",
      "Splitting data:\n",
      "  Train: 377 samples (90%)\n",
      "  Val: 42 samples (10%)\n",
      "✓ Detected elements from database: ['Mo', 'Nb', 'O', 'Ta', 'W']\n",
      "Building template graph...\n",
      "✓ Template created: 127 nodes, 1764 edges\n",
      "✓ Node features: 12 (pos: 3, one-hot: 5, props: 4)\n",
      "✓ Detected elements from database: ['Mo', 'Nb', 'O', 'Ta', 'W']\n",
      "Building template graph...\n",
      "✓ Template created: 127 nodes, 1764 edges\n",
      "✓ Node features: 12 (pos: 3, one-hot: 5, props: 4)\n",
      "\n",
      "✓ Dataloaders created:\n",
      "  Train: 12 batches\n",
      "  Val: 2 batches\n",
      "======================================================================\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "4. TRAIN MODEL\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrudiwinggla\u001b[0m (\u001b[33mrudiwinggla-montanuniversit-t-leoben\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>checkpoints/wandb/run-20251030_221421-94woeb4e</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/rudiwinggla-montanuniversit-t-leoben/diffusion-barrier/runs/94woeb4e' target=\"_blank\">20251030-221420-GNN</a></strong> to <a href='https://wandb.ai/rudiwinggla-montanuniversit-t-leoben/diffusion-barrier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/rudiwinggla-montanuniversit-t-leoben/diffusion-barrier' target=\"_blank\">https://wandb.ai/rudiwinggla-montanuniversit-t-leoben/diffusion-barrier</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/rudiwinggla-montanuniversit-t-leoben/diffusion-barrier/runs/94woeb4e' target=\"_blank\">https://wandb.ai/rudiwinggla-montanuniversit-t-leoben/diffusion-barrier/runs/94woeb4e</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Wandb initialized: 20251030-221420-GNN\n",
      "  Project: diffusion-barrier\n",
      "  URL: https://wandb.ai/rudiwinggla-montanuniversit-t-leoben/diffusion-barrier/runs/94woeb4e\n",
      "\n",
      "======================================================================\n",
      "STARTING TRAINING\n",
      "======================================================================\n",
      "Device: cuda\n",
      "Optimizer: AdamW (lr=0.0005, wd=0.01)\n",
      "Scheduler: plateau\n",
      "Wandb: Enabled (20251030-221420-GNN)\n",
      "Max epochs: 1000\n",
      "Early stopping patience: 50\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/klemens/aaa_New_code/251025_GNN_Gym/template_graph_builder.py:266: UserWarning: Issues encountered while parsing CIF: 1 fractional coordinates rounded to ideal values to avoid issues with finite precision.\n",
      "  structure = parser.parse_structures(primitive=False)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    1/1000 | Train Loss: 27.1064 | Val Loss: 28.5738 | Train MAE: 3.7725 | Val MAE: 3.6591 | LR: 5.00e-04\n",
      "  → New best model! Val loss: 28.5738\n",
      "Epoch    2/1000 | Train Loss: 21.2668 | Val Loss: 22.7020 | Train MAE: 3.6287 | Val MAE: 3.1744 | LR: 5.00e-04\n",
      "  → New best model! Val loss: 22.7020\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 182\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Wandb project: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39mwandb_project\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Wandb run name: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39mwandb_run_name\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01mor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto-generated\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 182\u001b[0m trainer, history \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcheckpoints\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m✓ Training completed! Trainer and history are available in variables.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[1], line 97\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(config, save_dir)\u001b[0m\n\u001b[1;32m     94\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(model, config, save_dir\u001b[38;5;241m=\u001b[39msave_dir)\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[0;32m---> 97\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# ========================================================================\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;66;03m# 5. SAVE FINAL MODEL\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;66;03m# ========================================================================\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m70\u001b[39m)\n",
      "File \u001b[0;32m~/aaa_New_code/251025_GNN_Gym/trainer.py:333\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, train_loader, val_loader, verbose)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_epoch \u001b[38;5;241m=\u001b[39m epoch\n\u001b[1;32m    332\u001b[0m \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[0;32m--> 333\u001b[0m train_loss, train_mae \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[38;5;66;03m# Validate\u001b[39;00m\n\u001b[1;32m    336\u001b[0m val_loss, val_mae \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidate(val_loader)\n",
      "File \u001b[0;32m~/aaa_New_code/251025_GNN_Gym/trainer.py:219\u001b[0m, in \u001b[0;36mTrainer.train_epoch\u001b[0;34m(self, train_loader)\u001b[0m\n\u001b[1;32m    216\u001b[0m total_mae \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m    217\u001b[0m n_batches \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 219\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;66;03m# Unpack tuple from dataloader\u001b[39;00m\n\u001b[1;32m    221\u001b[0m     initial_graphs, final_graphs, barriers \u001b[38;5;241m=\u001b[39m batch\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;66;03m# Move data to device\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/wandb/lib/python3.10/site-packages/torch/utils/data/dataloader.py:734\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    731\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    732\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    733\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 734\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    736\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    737\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    738\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    739\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    740\u001b[0m ):\n",
      "File \u001b[0;32m~/miniconda3/envs/wandb/lib/python3.10/site-packages/torch/utils/data/dataloader.py:790\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    789\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 790\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    791\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    792\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniconda3/envs/wandb/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/envs/wandb/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/aaa_New_code/251025_GNN_Gym/dataset.py:117\u001b[0m, in \u001b[0;36mDiffusionBarrierDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    114\u001b[0m barrier \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbackward_barrier_eV\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    116\u001b[0m \u001b[38;5;66;03m# Build graphs on-the-fly (fast with template!)\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m initial_graph, final_graph \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgraph_builder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_pair_graph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minitial_cif\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfinal_cif\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbackward_barrier\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbarrier\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m initial_graph, final_graph, barrier\n",
      "File \u001b[0;32m~/aaa_New_code/251025_GNN_Gym/template_graph_builder.py:400\u001b[0m, in \u001b[0;36mTemplateGraphBuilder.build_pair_graph\u001b[0;34m(self, initial_cif, final_cif, backward_barrier)\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;124;03mBuild graph pair for transition barrier prediction.\u001b[39;00m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;124;03mthe barrier for the transition (initial → final).\u001b[39;00m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    399\u001b[0m initial_graph \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcif_to_graph(initial_cif, barrier\u001b[38;5;241m=\u001b[39mbackward_barrier)\n\u001b[0;32m--> 400\u001b[0m final_graph \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcif_to_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfinal_cif\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbarrier\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbackward_barrier\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m initial_graph, final_graph\n",
      "File \u001b[0;32m~/aaa_New_code/251025_GNN_Gym/template_graph_builder.py:343\u001b[0m, in \u001b[0;36mTemplateGraphBuilder.cif_to_graph\u001b[0;34m(self, cif_path, barrier)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;124;03mConvert CIF file to graph using template.\u001b[39;00m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;124;03m    - num_nodes: N\u001b[39;00m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;66;03m# Read element sequence AND positions from CIF\u001b[39;00m\n\u001b[0;32m--> 343\u001b[0m elements, positions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_elements_and_positions_from_cif\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcif_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# Validate\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(elements) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtemplate_num_nodes:\n",
      "File \u001b[0;32m~/aaa_New_code/251025_GNN_Gym/template_graph_builder.py:266\u001b[0m, in \u001b[0;36mTemplateGraphBuilder._read_elements_and_positions_from_cif\u001b[0;34m(self, cif_path)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpymatgen\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcif\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CifParser\n\u001b[1;32m    265\u001b[0m parser \u001b[38;5;241m=\u001b[39m CifParser(cif_path)\n\u001b[0;32m--> 266\u001b[0m structure \u001b[38;5;241m=\u001b[39m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_structures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprimitive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    268\u001b[0m \u001b[38;5;66;03m# Get elements and positions\u001b[39;00m\n\u001b[1;32m    269\u001b[0m elements \u001b[38;5;241m=\u001b[39m [site\u001b[38;5;241m.\u001b[39mspecies_string \u001b[38;5;28;01mfor\u001b[39;00m site \u001b[38;5;129;01min\u001b[39;00m structure]\n",
      "File \u001b[0;32m~/miniconda3/envs/wandb/lib/python3.10/site-packages/pymatgen/io/cif.py:1313\u001b[0m, in \u001b[0;36mCifParser.parse_structures\u001b[0;34m(self, primitive, symmetrized, check_occu, on_error)\u001b[0m\n\u001b[1;32m   1311\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cif\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m   1312\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1313\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m struct \u001b[38;5;241m:=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprimitive\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msymmetrized\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_occu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_occu\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1314\u001b[0m             structures\u001b[38;5;241m.\u001b[39mappend(struct)\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mKeyError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/miniconda3/envs/wandb/lib/python3.10/site-packages/pymatgen/io/cif.py:1065\u001b[0m, in \u001b[0;36mCifParser._get_structure\u001b[0;34m(self, data, primitive, symmetrized, check_occu, min_thickness)\u001b[0m\n\u001b[1;32m   1063\u001b[0m \u001b[38;5;66;03m# Get occupancy\u001b[39;00m\n\u001b[1;32m   1064\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1065\u001b[0m     occu: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstr2float\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_atom_site_occupancy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1066\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mKeyError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m   1067\u001b[0m     occu \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/wandb/lib/python3.10/site-packages/pymatgen/io/cif.py:1519\u001b[0m, in \u001b[0;36mstr2float\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Remove uncertainty brackets from strings and return the float.\"\"\"\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1517\u001b[0m     \u001b[38;5;66;03m# Note that the ending ) is sometimes missing. That is why the code has\u001b[39;00m\n\u001b[1;32m   1518\u001b[0m     \u001b[38;5;66;03m# been modified to treat it as optional. Same logic applies to lists.\u001b[39;00m\n\u001b[0;32m-> 1519\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(\u001b[43mre\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msub\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43m(.+\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43m)*\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1521\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   1522\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(text, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(text) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/wandb/lib/python3.10/re.py:209\u001b[0m, in \u001b[0;36msub\u001b[0;34m(pattern, repl, string, count, flags)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msub\u001b[39m(pattern, repl, string, count\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, flags\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m    203\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the string obtained by replacing the leftmost\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;124;03m    non-overlapping occurrences of the pattern in string by the\u001b[39;00m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;124;03m    replacement repl.  repl can be either a string or a callable;\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;124;03m    if a string, backslash escapes in it are processed.  If it is\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;124;03m    a callable, it's passed the Match object and must return\u001b[39;00m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;124;03m    a replacement string to be used.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 209\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msub(repl, string, count)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._post_run_cell_hook of <wandb.sdk.wandb_init._WandbInit object at 0x7da0a75e2140>> (for post_run_cell), with arguments args (<ExecutionResult object at 7da4940a2140, execution_count=1 error_before_exec=None error_in_exec= info=<ExecutionInfo object at 7da4940a2260, raw_cell=\"\"\"\"\n",
      "Training Script for Diffusion Barrier Predicti..\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#W0sdW50aXRsZWQ%3D> result=None>,),kwargs {}:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "socket.send() raised exception.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Training Script for Diffusion Barrier Prediction - Jupyter Notebook Version\n",
    "\n",
    "Simple script to train a GNN model on diffusion barrier data in Jupyter.\n",
    "\n",
    "Usage in Jupyter:\n",
    "    %run train_notebook.py\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "from config import Config\n",
    "from template_graph_builder import TemplateGraphBuilder\n",
    "from dataset import create_dataloaders\n",
    "from model import create_model_from_config, count_parameters\n",
    "from trainer import Trainer\n",
    "from utils import save_model_for_inference, get_node_input_dim\n",
    "\n",
    "\n",
    "def train(config, save_dir: str = \"checkpoints\"):\n",
    "    \"\"\"\n",
    "    Main training function.\n",
    "    \n",
    "    Args:\n",
    "        config: Configuration object\n",
    "        save_dir: Directory to save checkpoints\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"DIFFUSION BARRIER PREDICTION - TRAINING\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"\\nDevice: {device}\")\n",
    "    \n",
    "    # ========================================================================\n",
    "    # 1. SETUP GRAPH BUILDER\n",
    "    # ========================================================================\n",
    "    print(\"\\n\" + \"-\"*70)\n",
    "    print(\"1. SETUP GRAPH BUILDER\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    builder = TemplateGraphBuilder(config)\n",
    "    node_input_dim = get_node_input_dim(builder)\n",
    "    \n",
    "    print(f\"\\n✓ Graph builder ready\")\n",
    "    print(f\"  Elements: {builder.elements}\")\n",
    "    print(f\"  Node input dim: {node_input_dim}\")\n",
    "    \n",
    "    # ========================================================================\n",
    "    # 2. CREATE MODEL\n",
    "    # ========================================================================\n",
    "    print(\"\\n\" + \"-\"*70)\n",
    "    print(\"2. CREATE MODEL\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    model = create_model_from_config(config, node_input_dim)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    params = count_parameters(model)\n",
    "    \n",
    "    print(f\"\\n✓ Model created\")\n",
    "    print(f\"  Architecture:\")\n",
    "    print(f\"    GNN layers: {config.gnn_num_layers}\")\n",
    "    print(f\"    GNN hidden dim: {config.gnn_hidden_dim}\")\n",
    "    print(f\"    MLP hidden dims: {config.mlp_hidden_dims}\")\n",
    "    print(f\"  Parameters:\")\n",
    "    print(f\"    Encoder: {params['encoder']:,}\")\n",
    "    print(f\"    Predictor: {params['predictor']:,}\")\n",
    "    print(f\"    Total: {params['total']:,}\")\n",
    "    \n",
    "    # ========================================================================\n",
    "    # 3. LOAD DATA\n",
    "    # ========================================================================\n",
    "    print(\"\\n\" + \"-\"*70)\n",
    "    print(\"3. LOAD DATA\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    train_loader, val_loader = create_dataloaders(\n",
    "        config,\n",
    "        val_split=config.val_split,\n",
    "        random_seed=config.random_seed\n",
    "    )\n",
    "    \n",
    "    # ========================================================================\n",
    "    # 4. TRAIN MODEL\n",
    "    # ========================================================================\n",
    "    print(\"\\n\" + \"-\"*70)\n",
    "    print(\"4. TRAIN MODEL\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    # Create trainer\n",
    "    trainer = Trainer(model, config, save_dir=save_dir)\n",
    "    \n",
    "    # Train\n",
    "    history = trainer.train(train_loader, val_loader, verbose=True)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # 5. SAVE FINAL MODEL\n",
    "    # ========================================================================\n",
    "    print(\"\\n\" + \"-\"*70)\n",
    "    print(\"5. SAVE FINAL MODEL\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    # Load best model\n",
    "    best_checkpoint_path = Path(save_dir) / \"best_model.pt\"\n",
    "    if best_checkpoint_path.exists():\n",
    "        trainer.load_checkpoint(str(best_checkpoint_path))\n",
    "        print(f\"\\n✓ Loaded best model from training\")\n",
    "    \n",
    "    # Save for inference\n",
    "    final_model_path = Path(save_dir) / \"final_model_for_inference.pt\"\n",
    "    save_model_for_inference(\n",
    "        model=trainer.model,\n",
    "        node_input_dim=node_input_dim,\n",
    "        elements=builder.elements,\n",
    "        config=config,\n",
    "        filepath=str(final_model_path),\n",
    "        metadata={\n",
    "            'best_val_loss': trainer.best_val_loss,\n",
    "            'total_epochs': trainer.current_epoch + 1,\n",
    "            'train_samples': len(train_loader.dataset),\n",
    "            'val_samples': len(val_loader.dataset) if val_loader else 0\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # ========================================================================\n",
    "    # 6. SUMMARY\n",
    "    # ========================================================================\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"TRAINING SUMMARY\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    print(f\"\\nTraining completed:\")\n",
    "    print(f\"  Total epochs: {trainer.current_epoch + 1}\")\n",
    "    print(f\"  Best val loss: {trainer.best_val_loss:.4f}\")\n",
    "    print(f\"  Train samples: {len(train_loader.dataset)}\")\n",
    "    if val_loader:\n",
    "        print(f\"  Val samples: {len(val_loader.dataset)}\")\n",
    "    \n",
    "    print(f\"\\nFiles saved:\")\n",
    "    print(f\"  Best checkpoint: {best_checkpoint_path}\")\n",
    "    print(f\"  Final model: {final_model_path}\")\n",
    "    print(f\"  History: {Path(save_dir) / 'training_history.json'}\")\n",
    "    \n",
    "    print(f\"\\nTo use this model for prediction:\")\n",
    "    print(f\"  from utils import load_model_for_inference\")\n",
    "    print(f\"  model, checkpoint = load_model_for_inference('{final_model_path}', config)\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70 + \"\\n\")\n",
    "    \n",
    "    return trainer, history\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# MAIN EXECUTION - Runs automatically when script is executed\n",
    "# ============================================================================\n",
    "\n",
    "# Create and configure\n",
    "config = Config()\n",
    "\n",
    "# Optional: Customize config here\n",
    "# config.epochs = 500\n",
    "# config.batch_size = 64\n",
    "# config.learning_rate = 0.001\n",
    "# config.use_wandb = True\n",
    "# config.wandb_run_name = \"my-experiment\"\n",
    "# config.wandb_tags = [\"baseline\", \"v1\"]\n",
    "\n",
    "# Run training\n",
    "print(\"Starting training with configuration:\")\n",
    "print(f\"  Epochs: {config.epochs}\")\n",
    "print(f\"  Batch size: {config.batch_size}\")\n",
    "print(f\"  Learning rate: {config.learning_rate}\")\n",
    "print(f\"  Scheduler: {config.scheduler_type}\")\n",
    "print(f\"  Wandb: {config.use_wandb}\")\n",
    "if config.use_wandb:\n",
    "    print(f\"  Wandb project: {config.wandb_project}\")\n",
    "    print(f\"  Wandb run name: {config.wandb_run_name or 'auto-generated'}\")\n",
    "\n",
    "trainer, history = train(config, save_dir=\"checkpoints\")\n",
    "\n",
    "print(\"\\n✓ Training completed! Trainer and history are available in variables.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wandb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
